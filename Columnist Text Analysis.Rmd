---
title: "R Notebook"
output: html_notebook
---

Analysis of Columnist Writings

```{r message=FALSE, warning=FALSE}
library(tidyverse)
library(tidytext)
library(stringr)
library(readr)
library(ggraph)
library(textclean)
library(readtext)
library(textstem)
library(textshape)
```

### Ideas:
   - Count of embedded quotes; word count related to quotes as a % of total word count.
   - Avg sentence length
   - What's that function or method for determining grade-level reading level
   - Avg. word count per story
   - Breadth of vocabulary; usage of arcane words which are not used by other columnists
   - Sentiment analysis
   - bigrams
   - Comparison of columnists on a matrix x:vocabulary; y: sentiment analysis
   - Bigrams/trigrams: level of redundancy

```{r}
columnist_articles <- function(path_) {
  df <- data.frame("docid"                  = character(),
                   "text"                   = character(),
                   "punctuation"            = character(),
                   "sans_quote"             = character(),
                   "punctuation_sans_quote" = character())

  files_ <- as.list(list.files(path = path_))

  for (i in 1 : length(files_)) {
    file_ <- paste0(path_, files_[i])
  
    # extract text from txt file.
    file_text <- as.data.frame(readtext(file = file_, encoding = "UTF-8"))

    # remove line breaks if they appear in the text
    file_text$text <- str_replace_all(file_text$text, "\n", " ")

    # removes "curly quotes" found in file; replace curly quotes with tildes
    file_text$text <- gsub("(\x93|\x94)", "\"", file_text$text, perl = T)

    # leave only the punctuation...
    file_text$punctuation  <- str_replace_all(file_text$text, "[:alpha:]", "")
    file_text$punctuation  <- str_replace_all(file_text$punctuation, "[:digit:]", "")
    file_text$punctuation  <- str_replace_all(file_text$punctuation, "[:space:]", "")
    
    # regex: remove (replace w/ zero space) text between double quotes;
    file_text$sans_quote <- gsub("\"[^\"]+\"", "", file_text$text)
    
    file_text$punctuation_sans_quote <- str_replace_all(file_text$sans_quote, "[:alpha:]", "")
    file_text$punctuation_sans_quote  <- str_replace_all(file_text$punctuation_sans_quote, "[:digit:]", "")
    file_text$punctuation_sans_quote  <- str_replace_all(file_text$punctuation_sans_quote, "[:space:]", "")
    
    
  
    # append to dataframe
    df <- rbind(df, file_text)
  }
     
   return(df)
}
```


```{r}

```

```{r}

xy_size <- function(series) {
  for (i in length(series)) {
    x = 0
    if (nchar(series[i]) > x) {
      x = nchar(series[i])
    }
  }
  width = floor(sqrt(x))
  rows = ceiling(x/width)
  
  return(as.list(c(width, rows)))
}

```

```{r}
extract_punct <- function(text,              # input text
                          sort = FALSE,      # order the characters?
                          vec_only = FALSE,  # return as char vector?
                          width = 80,        # width of output
                          colour = TRUE) {   # colour output?
  
  # Extract punctuation with regular expression
  punct_rx  <- "[\\.,:;!?\"\'\\()-_]"
  matches   <- regexpr(punct_rx, text)
  punct_vec <- regmatches(text, matches)
  
  # Sort alphabetically?
  if (sort) punct_vec <- punct_vec[order(punct_vec)]
  
  # Early return of character vector
  if (vec_only) return(punct_vec)
  
  # Colour the characters
  punct_vec <- sapply(
    punct_vec, switch,
    "."  = crayon::blue("."),
    "!"  = crayon::blue("!"),
    "?"  = crayon::blue("?"),
    ","  = crayon::yellow(","),
    ";"  = crayon::yellow(";"),
    ":"  = crayon::yellow(":"),
    "\"" = crayon::red("\""),
    "'"  = crayon::red("'"),
    "("  = crayon::silver("("),
    ")"  = crayon::silver(")")
  )
  
  # Print without colour
  if (!is.null(width) & !colour) {
    cat(names(punct_vec), sep = "", fill = width)
  }
  
  # Convoluted colour printing, requires flattening a matrix
  if (!is.null(width) & colour) {
    div_size <- length(punct_vec) %/% width * width
    mat_flat <- c(rbind("\n", matrix(punct_vec[1:div_size], nrow = width)))
    leftover <- c("\n", punct_vec[div_size:length(punct_vec)])
    cat(mat_flat[2:length(mat_flat)], leftover, sep = "")
  }
  
}
```



```{r}

t = df$text[1]
extract_punct(df$text[1],width= 10)


hulett_path <- "C:/Users/SAND8464/repos/columnists/Mike Hulett/"
df <- columnist_articles(hulett_path)



width = xy_size(df$punctuation)[[1]]
rows = xy_size(df$punctuation)[[2]]

punct_vect <- df$punctuation[1]
str_replace_all(punct_vect,"\"",'"')

mat_flat <- c(rbind("\n", matrix(punct_vect[1:width], nrow = rows)))


idx = 1
end = width
for (row in 1:rows) {
  text = str_sub(df$punctuation[1], idx, end)
  print(text)
  idx = idx + width
  end = end + width
}

print(text)
print(df$punctuation[1])

```


   

```{r}

text = 'While the Wuhan virus dominates, the presidential election looms only 206 days away. It was telling to see how efficiently the Democratic machine operated when it looked like the radical left\'s \"dear leader,\" comrade Sen. Bernie Sanders, I-Vt, had a chance of winning the nomination prior to dropping out of the race this week.  Upon receiving the call from Dem headquarters, Sen. Amy Klobuchar, D-Minn., Pete Buttigieg, Beto O\'Rourke, mini-Mike Bloomberg and even Sens. Kamala Harris, D-Calif., and Cory Booker, D-N.J., rushed to former Vice President Joe Biden’s side proclaiming their undying love and support. Biden, of course, is the friendly old politician that grins a lot but can’t seem to get things straight.  Liberal campaign managers have him pledging to raise taxes, open our borders, and advance the "Green New Deal."  Appearing confused, his attempts to extemporaneously opine on the Wuhan virus were awkward at best. Apparently that is deemed a small price for purging "the most dangerous president in American history."  Besides, Biden is an empty vessel that can easily be filled by House Speaker Nancy Pelosi, D-Calif., and her entourage of deep-state handlers.  Hmmm.  Could they be thinking that after inauguration they need only to keep him grinning in the background for a year or so, and then he proudly retires as our 46 th president?  His vice president, perhaps Klobuchar, would be sworn in. Game changer!  With cult-like support from news media, the federal bureaucracy and academia, what could possibly go wrong with that scheme? Actually, one significant problem involves former Ukraine Prosecutor General Viktor Shokin who was fired after then Vice President Biden threatened to withhold substantial American aide to Ukraine in a quid pro quo.  Shokin has successfully secured a Ukraine court order to investigate whether Biden violated any Ukraine laws.  At the time Biden was demanding he be fired, Shokin was investigating the corrupt Burisma Holdings Firm that just happened to be paying large sums of money to Hunter Biden. Documents released under the Freedom of Information Act indicate Burisma’s lawyers were pressuring our State Department in February 2016 to end corruption allegations against Burisma, invoking Hunter Biden’s name.  Recently, the Latvian government acknowledged it sent a warning to Ukraine officials in February 2016 flagging several Burisma financial transactions as "suspicious," including large payments to Hunter Biden. There is more.  Federal lawmakers are looking into how Joe, his brothers and sister, and Hunter all somehow became rather wealthy while Joe was vice president.  The Senate will be launching an investigation into lucrative Biden family financial dealings with Ukraine, China and Iraq.  Bummer.  The Dems might be forced to say: "Sorry, Joe, you have to go.\" Then what?  Fast forward to the Democrat Presidential Nomination Convention.  Masked delegates would be seated 6 feet apart.  Picture Barack and Michelle Obama, unmasked, stepping forward. Imagine Gallop’s "most admired woman in the world" saying: "My fellow Democrats and fellow Americans: The polls indicate Governor Andrew Cuomo might not win. Four more years of Donald J. Trump will spell the destruction of the United States of America. I am therefore offering my candidacy as a sure pathway to saving our Republic.\" Not a dry eye in the house; the Republic would be saved!'
```

```{r}
s <- split_sentence(df$text[5])
s
```

```{r}
sentences_df <- data.frame("docid" = character(),
                          "text" = character())

for (i in nrow(df$text)) {
  s <- split_sentence(df$text[i])
  print(s)
}

```

```{r}

```



```{r}
sw <- subset(stop_words) #, lexicon=='onix' | lexicon=='snowball')

# break text string into individual words array
# remove stop words (e.g. a, an, the, when, who, etc.);
# stop words come from tidytext package
# filter out words which appear as all numbers (e.g. 2001, 14) or
# combinations of letters/numbers (e.g 12EED,ABC123)
df2 <- df %>%
   unnest_tokens(input = "text", output = "word") %>%
   filter(str_detect(word, "[:alpha:]")) %>%
   anti_join(sw, by = "word") %>%
   count(word, sort = TRUE)

View(df2)
```


```{r}
df2$stem <-  lemmatize_words(df2$word)

df2 %>%
  count(stem, sort = TRUE) %>%
  View()
```


```{r}
bigram_df <- df %>%
  unnest_tokens(df, text, token = "ngrams", n = 2) %>%
  separate(df, c("w1", "w2", "w3"), sep = " ") %>%
  filter(!w1 %in% sw$word) %>%
  filter(!w2 %in% sw$word) %>%
  filter(!w3 %in% sw$word) %>%
  count(w1, w2, w3, sort = TRUE)

View(bigram_df)
```
 
 